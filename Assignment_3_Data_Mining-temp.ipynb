{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment 3 - Data Mining.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "62erSAPKMPdE"
      },
      "source": [
        "Assignment 3 [Part 1/2]\n",
        "\n",
        "\n",
        "1. Consider a dataset  D  that contains only two observations  x1=(1,1)  and  x2=(−1,−1) . Suppose that the class of the first observation is  y1=0  and that the class of the second observation is  y2=1 . How would a 1-nearest neighbour classifier based on the Euclidean distance classify the observation  x=(2,3) ? What are the distances between this new observation and each observation in the dataset? "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t0kTmE38W6sq"
      },
      "source": [
        "Solution:\n",
        "\n",
        "The 1-nearest neighbour classifier classify the observation X=(2,3) as 0 based on the euclidean distance.\n",
        "\n",
        "\n",
        "The distnace between new observation is given below. \n",
        "\n",
        "\n",
        "(X1, Y1) = (1, 1)\n",
        "\n",
        "(X2, Y2) = (2, 3)\n",
        "\n",
        "d=sqrt((2−1)2+(3−1)2)\n",
        "\n",
        "d=2.236068\n",
        "\n",
        "For \n",
        "(X1, Y1) = (-1, -1)\n",
        "(X2, Y2) = (2, 3)\n",
        "\n",
        "d=sqrt((2−(−1))2+(3−(−1))2)\n",
        "\n",
        "d=**5**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DF_EeS9OawJ_"
      },
      "source": [
        "2. Consider a dataset  D  that only contains observations of two different classes. Explain why a  k -nearest neighbour classifier does not need a tie-breaking policy when k is odd."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5GcSf_KJml9b"
      },
      "source": [
        "Solution: \n",
        "\n",
        "Given that dataset contains only 2 classes and K is odd, the classifier never be in tie-breaking scenario because the number of surrounded points total will leads to majority either one of the class. \n",
        "\n",
        "Example when k= 7, Class 0= 4 (data points) and class 1 = 3(data points). The class 0 have majoirty points. we can observe when K is odd it never be in tie-breaking policy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hKg2UPp9qEUt"
      },
      "source": [
        "3. Explain why a classifier that obtains an accuracy of  99.9%  can be terrible for some datasets."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a_G8FFrjqRdH"
      },
      "source": [
        "Solution: \n",
        "\n",
        " \n",
        " A classifier that obtains an accuracy of 99.9% can be terrible for some datasets because of class imbalance. If 99.9% of the observations in Dataset belong  to class y, a classifier that predicts y for every observation has 99.9% accuracy and classifier fails terrible for other classes.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kdNg0F-s66JS"
      },
      "source": [
        "4. Consider a classifier tasked with predicting whether an observation belongs to class  y  (positive class). Suppose that this classifier has precision  1.0  and recall  0.1  on a test dataset. If this classifier predicts that an observation does not belong to class  y , should it be trusted? Should it be trusted if it predicts that the observation belongs to class  y ? "
      ]
    }
  ]
}