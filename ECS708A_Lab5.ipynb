{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ECS708A_Lab5.ipynb","provenance":[],"private_outputs":true,"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"9MsgMYnK1tN3","colab_type":"text"},"source":["# <font color='gray'> Lab 5: More on ROC Curves</font>"]},{"cell_type":"markdown","metadata":{"id":"HhBuFH8z2LP0","colab_type":"text"},"source":["In this exercise, we will explore the ROC curves as a means to evaluate classifiers, and the benefits they bring compared to simple accuracy metrics. This is not a graded activity, but we recommend that you attemp it to enhance your understanding."]},{"cell_type":"markdown","metadata":{"id":"FBLLzWFD2dvO","colab_type":"text"},"source":["#### 0. In the following, we will set up a two-class classification problem based on the iris flower data you are already familiar with. As you can see the data is quite overlapped, so it will be hard to classify accurately (we have chosen the flower classes that are the most difficult to separate)."]},{"cell_type":"code","metadata":{"id":"vtVrmu511vbK","colab_type":"code","colab":{}},"source":["import matplotlib.pyplot as plt\n","from sklearn import datasets\n","\n","# import some data to play with\n","iris = datasets.load_iris()\n"," # we only take the first two features, but also only the two difficult classes:\n","idx = (iris.target == 1)|(iris.target == 2)\n","X = iris.data[idx, :2] \n","Y = iris.target[idx]\n","\n","fig = plt.figure(figsize=(7, 7))\n","ax = fig.add_subplot(111)\n","ax.set_aspect('equal')\n","\n","colors = (\"green\", \"blue\")\n","marker_list = ['o', 'x']\n","\n","\n","for l in [1, 2]:\n","  ax.scatter(X[Y == l, 0], X[Y == l, 1],\n","             marker=marker_list[l-1], s=70,\n","             c=colors[l-1], edgecolors='none',\n","             label='{:d} ({:s})'.format(l, iris.target_names[l]))\n","\n","ax.legend(fontsize=12,loc='upper left')\n","ax.set_xlabel(iris.feature_names[0], fontsize=14)\n","ax.set_ylabel(iris.feature_names[1], fontsize=14)\n","ax.grid(alpha=0.3)\n","ax.set_xlim(X[:, 0].min() - 0.5, X[:, 0].max() + 0.5)\n","ax.set_ylim(X[:, 1].min() - 0.5, X[:, 1].max() + 0.5)\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7eyWtjJqBtsZ","colab_type":"text"},"source":["#### 1. The following cell trains NaÃ¯ve Bayes (NB) and Logistic Regression (LR) classifiers on the train data. Observe the decision boundaries in the figures."]},{"cell_type":"code","metadata":{"id":"Yz2xKum8_Bkp","colab_type":"code","colab":{}},"source":["from sklearn.naive_bayes import GaussianNB\n","from sklearn.linear_model import LogisticRegression\n","import numpy as npC curves as a means to evaluate classifiers, and the benefits they bring compared to simple accuracy\n","from google.colab import widgets\n","\n","\n","grid = widgets.Grid(1, 2)\n","\n","\n","Xtr = X[::2]\n","Ytr = Y[::2]\n","Xte = X[1::2]\n","Yte = Y[1::2]\n","\n","LR_classifier = LogisticRegression(solver='lbfgs')\n","LR_classifier.fit(Xtr, Ytr)\n","\n","NB_classifier = GaussianNB()\n","NB_classifier.fit(Xtr, Ytr)\n","\n","# Now to plot the decision regions:\n","\n","with grid.output_to(0, 0):\n","  # first the logistic regression classifier:\n","  fig = plt.figure(1, figsize=(7, 7))\n","  # fig, axs = plt.subplots(1, 2)\n","  ax = fig.add_subplot(111)\n","  ax.set_aspect('equal')\n","\n","  x_min = min(Xtr[:, 0].min(), Xte[:, 0].min()) - .5 # min of the x axis\n","  x_max = max(Xtr[:, 0].max(), Xte[:, 0].max()) + .5 # max of the x axis\n","  y_min = min(Xtr[:, 1].min(), Xte[:, 1].min()) - .5 # min of the y axis\n","  y_max = max(Xtr[:, 1].max(), Xte[:, 1].max()) + .5 # max of the y axis\n","  h = .02  # step size in the mesh\n","  xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n","\n","\n","  Z = LR_classifier.predict(np.c_[xx.ravel(), yy.ravel()])\n","  Z = Z.reshape(xx.shape)\n","  plt.pcolormesh(xx, yy, Z, cmap=plt.cm.Pastel2)\n","\n","  # plotting the train points with reduced opacity:\n","  marker_list = ['o', 'x']\n","  for l in [1, 2]:\n","    plt.scatter(Xtr[Ytr == l, 0], Xtr[Ytr == l, 1], \n","                marker=marker_list[l-1], color=colors[l-1], s=70, alpha=0.3,)\n","  # plotting the test points in full opacity:\n","  for l in [1, 2]:\n","    plt.scatter(Xte[Yte == l, 0], Xte[Yte == l, 1], \n","                marker=marker_list[l-1], color=colors[l-1], s=70, \n","                label='{:d} ({:s})'.format(l, iricise 1: The following cell contains a function that given a classifier and a threshold and some (test) samples, returns the TPR and FPR. Use this function to try a number of thresholds and fill in the TPR ans.target_names[l]))\n","cise 1: The following cell contains a function that given a classifier and a threshold and some (test) samples, returns the TPR and FPR. Use this function to try a number of thresholds and fill in the TPR an\n","  ax.set_title('Decision Boundary for Logistic Regression', fontsize=16)\n","  ax.set_xlabel(iris.feature_names[0], fontsize=14)\n","  ax.set_ylabel(iris.feature_names[1], fontsize=14)\n","  ax.set_xlim(xx.min(), xx.max())\n","  ax.set_ylim(yy.min(), yy.max())\n","  ax.legend(fontsize=12, loc='upper left')\n","  ax.grid(alpha=0.3)\n","  plt.show()\n","\n","with grid.output_to(0, 1):\n","  # Now the Naive Bayes classifier:\n","  fig = plt.figure(1, figsize=(7, 7))\n","  ax = fig.add_subplot(111)\n","  ax.set_aspect('equal')\n","\n","  Z = NB_classifier.predict(np.c_[xx.ravel(), yy.ravel()])\n","  Z = Z.reshape(xx.shape)\n","  plt.pcolormesh(xx, yy, Z, cmap=plt.cm.Pastel2)\n","\n","  # plotting the train points with reduced opacity:\n","  marker_list = ['o', 'x']\n","  for l in [1, 2]:\n","    plt.scatter(Xtr[Ytr == l, 0], Xtr[Ytr == l, 1], \n","                marker=marker_list[l-1], color=colors[l-1], s=70, alpha=0.3,)\n","  # plotting the test points in full opacity:\n","  for l in [1, 2]:\n","    plt.scatter(Xte[Yte == l, 0], Xte[Yte == l, 1]cise 1: The following cell contains a function that given a classifier and a threshold and some (test) samples, returns the TPR and FPR. Use this function to try a number of thresholds and fill in the TPR an, \n","                marker=marker_list[l-1], color=colcise 1: The following cell contains a function that given a classifier and a threshold and some (test) samples, returns the TPR and FPR. Use this function to try a number of thresholds and fill in the TPR anors[l-1], s=70, \n","                label='{:d} ({:s})'.format(l, iris.target_names[l]))\n","\n","  ax.set_title('Decision Boundary for Naive Bayes', fontsize=16)\n","  ax.set_xlabel(iris.feature_names[0], fontsize=14)\n","  ax.set_ylabel(iris.feature_names[1], fontsize=14)\n","  ax.set_xlim(xx.min(), xx.max())\n","  ax.set_ylim(yy.min(), yy.max())\n","  ax.legend(fontsize=12, loc='upper left')\n","  ax.grid(alpha=0.3)\n","  plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PE5VabQC9Q2j","colab_type":"text"},"source":["#### 2. Typically we make decisions based on which class has greater probability (i.e., which class has > 0.5 probability in the binary case). However, sometimes it is more important to detect one class than the other. In such cases we can tune the threshold to prefer one class or the other. In the following code, you can set the threshold value. Try some threshold values between 0 and 1. Observe how the decision boundaries visually change in the two figures, as well as the displayed confusion matrices."]},{"cell_type":"code","metadata":{"id":"Ee-HBn1j9Rdx","colab_type":"code","colab":{}},"source":["from sklearn.metrics import confusion_matrix\n","\n","\n","threshold = 0.7\n","\n","\n","grid = widgets.Grid(1, 2)\n","\n","\n","with grid.output_to(0, 0):\n","  # first for LR classifier:\n","  predict_index = LR_classifier.predict_proba(np.c_[xx.ravel(), yy.ravel()])[:,0]>threshold\n","  Z = np.ones(predict_index.shape, dtype=int)\n","  Z[~predict_index] = 2\n","  Z = Z.reshape(xx.shape)\n","\n","\n","  fig = plt.figure(1, figsize=(7, 7))\n","  ax = fig.add_subplot(111)\n","  ax.set_aspect('equal')\n","\n","  plt.pcolormesh(xx, yy, Z, cmap=plt.cm.Pastel2)\n","\n","  # plotting the train points with reduced opacity:\n","  marker_list = ['o', 'x']\n","  for l in [1, 2]:\n","    plt.scatter(Xtr[Ytr == l, 0], Xtr[Ytr == l, 1], \n","                marker=marker_list[l-1], color=colors[l-1], s=70, alpha=0.3,)\n","  # plotting the test points in full opacity:\n","  for l in [1, 2]:\n","    plt.scatter(Xte[Yte == l, 0], Xte[Yte == l, 1], \n","                marker=marker_list[l-1], color=colors[l-1], s=70, \n","                label='{:d} ({:s})'.format(l, iris.target_names[l]))\n","\n","  ax.set_title('Decision Boundary for Logistic Regression with threshold={}'.format(threshold), fontsize=16)\n","  ax.set_xlabel(iris.feature_names[0], fontsize=14)\n","  ax.set_ylabel(iris.feature_names[1], fontsize=14)\n","  ax.set_xlim(xx.min(), xx.max())\n","  ax.set_ylim(yy.min(), yy.max())cise 1: The following cell contains a function that given a classifier and a threshold and some (test) samples, returns the TPR and FPR. Use this function to try a number of thresholds and fill in the TPR an\n","  ax.legend(fontsize=12, loc='upper left')\n","  ax.grid(alpha=0.3)\n","  plt.show()\n","  \n","  predict_index = LR_classifier.predict_proba(Xte)[:,0]>threshold\n","  Yte_pred = np.ones(predict_index.shape, dtype=int)\n","  Yte_pred[~predict_index] = 2\n","\n","  print('Confusion matrix (on test data):')\n","  print(confusion_matrix(Yte, Yte_pred))\n","\n","\n","\n","\n","with grid.output_to(0, 1):\n","  # Now the Naive Bayes classifier:\n","  fig = plt.figure(1, figsize=(7, 7))\n","  ax = fig.add_subplot(111)\n","  ax.set_aspect('equal')\n","\n","  predict_index = NB_classifier.predict_proba(np.c_[xx.ravel(), yy.ravel()])[:,0]>threshold\n","  Z = np.ones(predict_index.shape, dtype=int)\n","  Z[~predict_index] = 2\n","  Z = Z.reshape(xx.shape)\n","  plt.pcolormesh(xx, yy, Z, cmap=plt.cm.Pastel2)\n","\n","  # plotting the train points with reduced opacity:\n","  marker_list = ['o', 'x']\n","  for l in [1, 2]:\n","    plt.scatter(Xtr[Ytr == l, 0], Xtr[Ytr == l, 1], \n","                marker=marker_list[l-1], color=colors[l-1], s=70, alpha=0.3,)\n","  # plotting the test points in full opacity:\n","  for l in [1, 2]:\n","    plt.scatter(Xte[Yte == l, 0], Xte[Yte == l, 1], \n","                marker=marker_list[l-1], color=colors[l-1], s=70, \n","                label='{:d} ({:s})'.format(l, iris.target_names[l]))\n","\n","  ax.set_title('Decision Boundary for Naive Bayes with threshold={}'.format(threshold), fontsize=16)\n","  ax.set_xlabel(iris.feature_names[0], fontsize=14)\n","  ax.set_ylabel(iris.feature_names[1], fontsize=14)\n","  ax.set_xlim(xx.min(), xx.max())\n","  ax.set_ylim(yy.min(), yy.max())\n","  ax.legend(fontsize=12, loc='upper left')\n","  ax.grid(alpha=0.3)\n","  plt.show()\n","\n","  predict_index = NB_classifier.predict_proba(Xte)[:,0]>threshold\n","  Yte_pred = np.ones(predict_index.shape, dtype=int)\n","  Yte_pred[~predict_index] = 2\n","  print('Confusion matrix (on test data):')\n","  print(confusion_matrix(Yte, Yte_pred))cise 1: The following cell contains a function that given a classifier and a threshold and some (test) samples, returns the TPR and FPR. Use this function to try a number of thresholds and fill in the TPR an\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zCRbA_zYLL21","colab_type":"text"},"source":["#### 3. The threshold to use provides a parameter for the user of the classifier to control. In this way they can for example maintain a maximum false positive rate, or a minimum true positive rate. \n","\n","One way to evaluate a classifier so its suitability for any application can be checked is to calculate the true positive rate (TPR) and the false positive rate (FPR) for the entire range of thresholds.\n","\n","\n","---\n","#### <font color='maroon'>**Exercise 1:** The following cell contains a function that given a classifier and a threshold and some (test) samples, returns the TPR and FPR. Use this function to try a number of thresholds and fill in the TPR and FPR vectors. Plot TPR (y-axis) against FPR (x-axis) to visualise the resulting ROC curve. Provide both your code and the figure. </ins></font>\n","--- "]},{"cell_type":"code","metadata":{"id":"S35Br4JsLUsf","colab_type":"code","colab":{}},"source":["def compute_tpr_fpr(classifier, threshold, Xte, Yte):\n","  classes = np.unique(Yte)\n","  predict_index = classifier.predict_proba(Xte)[:,0]>threshold\n","  true_positives = sum((Yte == classes[0])&(predict_index))\n","  false_positives = sum((Yte == classes[1])&(predict_index))\n","  all_actual_positives = sum(Yte == classes[0])\n","  all_actual_negatives = sum(Yte == classes[1])\n","  \n","  TPR = true_positives/all_actual_positives\n","  FPR = false_positives/all_actual_negativescise 1: The following cell contains a function that given a classifier and a threshold and some (test) samples, returns the TPR and FPR. Use this function to try a number of thresholds and fill in the TPR an\n","  return TPR, FPRcise 1: The following cell contains a function that given a classifier and a threshold and some (test) samples, returns the TPR and FPR. Use this function to try a number of thresholds and fill in the TPR an\n","\n","# just for testing the function:\n","threshold = 0.5\n","TPR, FPR = compute_tpr_fpr(LR_classifier, threshold, Xte, Yte)\n","print(TPR, FPR)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"HtOGkC_OP5Gt","colab_type":"code","colab":{}},"source":["# Now, write your code here (to compute a 1-d arrays of TPR and FRP for different \n","# values of the threshold)\n","\n","\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"MjPmhe1pQ15c","colab_type":"code","colab":{}},"source":["# Here is a sample plotting code, once you get the arrays of TPR and FPR for \n","# each of the classifiers\n","\n","\n","plt.figure(figsize=(8,8))\n","plt.title('ROC Curves')\n","plt.plot([0, 1], [0, 1], 'k--')\n","plt.axis([-0.005, 1, 0, 1.005])\n","plt.xticks(np.arange(0,1, 0.05), rotation=90)\n","plt.xlabel(\"False Positive Rate\")\n","plt.ylabel(\"True Positive Rate\")\n","    \n","\n","plt.plot(FPR_LR, TPR_LR, linewidth=3, alpha=0.7, label='Logistic Regression')\n","\n","plt.plot(FPR_NB, TPR_NB, linewidth=3, alpha=0.7, label='Naive Bayes')\n","\n","plt.legend(loc='best', fontsize=14)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MiXpqgHYLyYc","colab_type":"text"},"source":["From the ROC curve, you can see that one classifier or the other may be\n","slightly preferable depending on the required TPR/FPR constraints of the\n","particular application. The Area under the ROC curve is the preferred metric to compare two curves independently of a specific choice of threshold. "]},{"cell_type":"markdown","metadata":{"id":"g-4PB9vIL-My","colab_type":"text"},"source":["---\n","#### <font color='maroon'>**Exercise 2:** Compare the AUC of the ROCs of the two classifiers. Which one is preferable according to the AUC metric? </ins></font>\n","--- "]},{"cell_type":"code","metadata":{"id":"V3ETx0utQUpl","colab_type":"code","colab":{}},"source":["# your code here to compute the AUC (you don't have to include the code in your answer!)\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dqAtPRtaMRhz","colab_type":"text"},"source":["---\n","#### <font color='maroon'>**Exercise 3:** Suppose that for a particular application, the maximum allowed FPR is 0.16.  Which classifier is preferable? Which classifier obtains the maximum TPR given this FPR constraint? </ins></font>\n","--- "]},{"cell_type":"code","metadata":{"id":"lfQwrZ-IQSmn","colab_type":"code","colab":{}},"source":["# your code here (again, you don't need to include your code for the answer!)"],"execution_count":0,"outputs":[]}]}